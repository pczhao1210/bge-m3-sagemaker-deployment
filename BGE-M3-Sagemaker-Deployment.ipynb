{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df0642b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install huggingface_hub==0.26.1 -Uqq -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "!pip install -Uqq sagemaker -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f273307",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -Uqq packaging==24.1 -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084575bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4111a440",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install modelscope -i https://pypi.tuna.tsinghua.edu.cn/simple -Uqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c947ad98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelscope.hub.snapshot_download import snapshot_download\n",
    "from pathlib import Path\n",
    "\n",
    "local_model_path = Path(\"./bge-m3-model\")\n",
    "\n",
    "local_model_path.mkdir(exist_ok=True)\n",
    "model_name = \"Xorbits/bge-m3\"\n",
    "commit_hash = \"v0.0.1\"\n",
    "\n",
    "snapshot_download(model_name, revision=commit_hash, cache_dir=local_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e72ed66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import image_uris\n",
    "import boto3\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "\n",
    "role = sagemaker.get_execution_role()  # execution role for the endpoint\n",
    "sess = sagemaker.session.Session()  # sagemaker session for interacting with different AWS APIs\n",
    "bucket = sess.default_bucket()  # bucket to house artifacts\n",
    "\n",
    "region = sess._region_name\n",
    "account_id = sess.account_id()\n",
    "\n",
    "s3_client = boto3.client(\"s3\")\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "smr_client = boto3.client(\"sagemaker-runtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe00ede2",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_model_prefix = \"GenBI-Model/bge-m3-model\"  # folder where model checkpoint will go\n",
    "if region in ['cn-north-1', 'cn-northwest-1']:\n",
    "    model_snapshot_path = f'{local_model_path}/{model_name}'\n",
    "else:\n",
    "    model_snapshot_path = list(local_model_path.glob(\"**/snapshots/*\"))[0]\n",
    "s3_code_prefix = \"GenBI-Model/bge_m3_deploy_code\"\n",
    "print(f\"s3_code_prefix: {s3_code_prefix}\")\n",
    "print(f\"model_snapshot_path: {model_snapshot_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7522f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp --recursive {model_snapshot_path} s3://{bucket}/{s3_model_prefix}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2114c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_image_uri = (\n",
    "    f\"763104351884.dkr.ecr.{region}.amazonaws.com/djl-inference:0.23.0-deepspeed0.9.5-cu118\"\n",
    "    \n",
    ")\n",
    "\n",
    "#中国区需要替换为下面的image_uri\n",
    "if region in ['cn-north-1', 'cn-northwest-1']:\n",
    "    inference_image_uri = (\n",
    "        f\"727897471807.dkr.ecr.{region}.amazonaws.com.cn/djl-inference:0.23.0-deepspeed0.9.5-cu118\"\n",
    "    )\n",
    "\n",
    "print(f\"Image going to be used is ---- > {inference_image_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a24fd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p bge_m3_deploy_code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be77b26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile bge_m3_deploy_code/model.py\n",
    "from djl_python import Input, Output\n",
    "import torch\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "# from FlagEmbedding import FlagModel\n",
    "from FlagEmbedding import BGEM3FlagModel\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'--device={device}')\n",
    "\n",
    "def load_model(properties):\n",
    "    tensor_parallel = properties[\"tensor_parallel_degree\"]\n",
    "    model_location = properties['model_dir']\n",
    "    if \"model_id\" in properties:\n",
    "        model_location = properties['model_id']\n",
    "    logging.info(f\"Loading model in {model_location}\")\n",
    "\n",
    "    # model =  FlagModel(model_location)\n",
    "    model = BGEM3FlagModel(model_location, use_fp16=True)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = None\n",
    "\n",
    "def handle(inputs: Input):\n",
    "    global model\n",
    "    if not model:\n",
    "        model = load_model(inputs.get_properties())\n",
    "\n",
    "    if inputs.is_empty():\n",
    "        return None\n",
    "    data = inputs.get_as_json()\n",
    "    \n",
    "    input_sentences = None\n",
    "    inputs = data[\"inputs\"]\n",
    "    if isinstance(inputs, list):\n",
    "        input_sentences = inputs\n",
    "    else:\n",
    "        input_sentences =  [inputs]\n",
    "        \n",
    "    is_query = None\n",
    "    if \"is_query\" in data:\n",
    "        is_query = data[\"is_query\"]\n",
    "    instruction = None\n",
    "    if \"instruction\" in data:  \n",
    "        instruction = data[\"instruction\"]\n",
    "    max_length = 8192\n",
    "    if max_length in data:\n",
    "        max_length = data[\"max_length\"]\n",
    "    logging.info(f\"inputs: {input_sentences}\")\n",
    "    logging.info(f\"is_query: {is_query}\")\n",
    "    logging.info(f\"instruction: {instruction}\")\n",
    "    \n",
    "    if is_query and instruction:\n",
    "        input_sentences = [ instruction + sent for sent in input_sentences ]\n",
    "        \n",
    "    sentence_embeddings =  model.encode(input_sentences, max_length=max_length)['dense_vecs']\n",
    "    \n",
    "    #result = {\"sentence_embeddings\": sentence_embeddings}\n",
    "    return Output().add_as_json(sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1878bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"option.s3url ==> s3://{bucket}/{s3_model_prefix}/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b110fcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists(\"bge_m3_deploy_code\"):\n",
    "    os.mkdir(\"bge_m3_deploy_code\")\n",
    "\n",
    "with open('bge_m3_deploy_code/serving.properties', 'w') as f:\n",
    "    f.write(\"engine=Python\")\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"option.tensor_parallel_degree=1\")\n",
    "    f.write(\"\\n\")\n",
    "    f.write(f\"option.s3url=s3://{bucket}/{s3_model_prefix}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61ddc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile bge_m3_deploy_code/requirements.txt\n",
    "-i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "FlagEmbedding==1.2.3\n",
    "transformers==4.42.0\n",
    "torch>=2.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c240645",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm s2e_model.tar.gz\n",
    "!cd bge_m3_deploy_code && rm -rf \".ipynb_checkpoints\"\n",
    "!tar czvf s2e_model.tar.gz bge_m3_deploy_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905908a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_code_artifact = sess.upload_data(\"s2e_model.tar.gz\", bucket, s3_code_prefix)\n",
    "print(f\"S3 Code or Model tar ball uploaded to --- > {s3_code_artifact}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d373ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.utils import name_from_base\n",
    "import boto3\n",
    "\n",
    "model_name = name_from_base(\"bge-m3\") #Note: Need to specify model_name\n",
    "print(model_name)\n",
    "print(f\"Image going to be used is ---- > {inference_image_uri}\")\n",
    "\n",
    "create_model_response = sm_client.create_model(\n",
    "    ModelName=model_name,\n",
    "    ExecutionRoleArn=role,\n",
    "    PrimaryContainer={\n",
    "        \"Image\": inference_image_uri,\n",
    "        \"ModelDataUrl\": s3_code_artifact\n",
    "    },\n",
    "    \n",
    ")\n",
    "model_arn = create_model_response[\"ModelArn\"]\n",
    "\n",
    "print(f\"Created Model: {model_arn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b1a63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_config_name = f\"{model_name}-config\"\n",
    "endpoint_name = f\"{model_name}-endpoint\"\n",
    "\n",
    "endpoint_config_response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"variant1\",\n",
    "            \"ModelName\": model_name,\n",
    "            \"InstanceType\": \"ml.g4dn.xlarge\",\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            # \"VolumeSizeInGB\" : 400,\n",
    "            # \"ModelDataDownloadTimeoutInSeconds\": 2400,\n",
    "            \"ContainerStartupHealthCheckTimeoutInSeconds\": 15*60,\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "endpoint_config_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ba264f",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_endpoint_response = sm_client.create_endpoint(\n",
    "    EndpointName=f\"{endpoint_name}\", EndpointConfigName=endpoint_config_name\n",
    ")\n",
    "print(f\"Created Endpoint: {create_endpoint_response['EndpointArn']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59203699",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp[\"EndpointStatus\"]\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "while status == \"Creating\":\n",
    "    time.sleep(60)\n",
    "    resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = resp[\"EndpointStatus\"]\n",
    "    print(\"Status: \" + status)\n",
    "\n",
    "print(\"Arn: \" + resp[\"EndpointArn\"])\n",
    "print(\"Status: \" + status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733b34e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector_by_sm_endpoint(questions, sm_client, endpoint_name):\n",
    "    parameters = {\n",
    "    }\n",
    "\n",
    "    response_model = sm_client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        Body=json.dumps(\n",
    "            {\n",
    "                \"inputs\": questions,\n",
    "                \"is_query\": True,\n",
    "                \"instruction\" :  \"Represent this sentence for searching relevant passages:\"\n",
    "            }\n",
    "        ),\n",
    "        ContentType=\"application/json\",\n",
    "    )\n",
    "    # 中文instruction => 为这个句子生成表示以用于检索相关文章：\n",
    "    json_str = response_model['Body'].read().decode('utf8')\n",
    "    json_obj = json.loads(json_str)\n",
    "    embeddings = json_obj\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533b21fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts1 = [\"你好啊，大聪明\"]\n",
    "\n",
    "emb = get_vector_by_sm_endpoint(prompts1, smr_client, endpoint_name)\n",
    "print(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240aaed9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
